{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AWS Public Sector Machine Learning Workshop\n",
    "\n",
    "**Part 1: Predicting fraudulent Medicare providers using XGBoost**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 2003, the US federal government has made approximately $\\$$1.7 trillion in improper payments, with an estimated $\\$$206 billion made in FY 2020 alone. Improper payments are now anticipated to increase proportionally to new levels of federal spending, from the $\\$$1 trillion infrastructure bill, to the anticipated $\\$$3.5 trillion budget reconciliation plan\n",
    "\n",
    "How can we go beyond basic heuristic rulesets to help agencies fight improper payments at scale? \n",
    "\n",
    "Using preprocessed data from the Centers for Medicare & Medicaid Services (CMS), we'll demonstrate how to train a classification model to predict fraudulent Medicare providers using the XGBoost algorithm.\n",
    "\n",
    "**Let's get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Setup\n",
    "<a id=section_1_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Prerequisites\n",
    "<a id=section_1_1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Import packages and modules\n",
    "<a id=section_1_2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import sklearn\n",
    "from math import sqrt\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import RandomCutForest\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sklearn.datasets import dump_svmlight_file  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.datasets import dump_svmlight_file   \n",
    "from collections import Counter\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3 Global config settings\n",
    "<a id=section_1_3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow viewing of all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.4 Global config variables\n",
    "<a id=section_1_4></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IAM role and SakeMaker session\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# Set service clients\n",
    "s3_client = boto3.client('s3')\n",
    "#sm_client = boto3.client('sagemaker')\n",
    "#smr_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# S3 settings\n",
    "bucket = session.default_bucket() # Update as needed\n",
    "prefix = 'fraud-detect-demo' # Update as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Exploratory Data Analysis\n",
    "<a id=section_2_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Unzipping the prepocessed data file\n",
    "<a id=section_2_1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!gzip -d processed_data_classification.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2 Read the preprocessed medicare data\n",
    "<a id=section_2_2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_data_classification_v2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3 View the dimensions of the dataset (#rows, #cols)\n",
    "<a id=section_2_3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.4 Visually inspect the first few rows in the dataset\n",
    "<a id=section_2_4></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.5 Check data for any nulls\n",
    "<a id=section_2_5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.6 Check for imbalance\n",
    "<a id=section_2_6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the target (fraudulent_provider) value counts to check for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fraudulent_provider'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the majority of data is non-fraudulent. We will need to rebalance the data using sampling techniques that are designed specifically for imbalanced problems to improve the performance of the model.We use the Random Under Sampler and Over Sampling techniques from imblearn to do this (http://glemaitre.github.io/imbalanced-learn/api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.7 Display correlation matix\n",
    "<a id=section_2_7></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(36, 36))\n",
    "sns.heatmap(data.corr(), annot = True, fmt = '.2f', cmap='RdYlGn_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Preprocessing\n",
    "<a id=section_3_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1 Data Preparation\n",
    "<a id=section_3_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove column headers from dataset as SageMaker does not need headers for processing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing column headers from CSV file\n",
    "feature_columns = data.columns[1:]\n",
    "label_column = data.columns[0]\n",
    "\n",
    "# Setting the datatype to float32\n",
    "features = data[feature_columns].values.astype('float32')\n",
    "labels = (data[label_column].values).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a train and test to evaluate the performance of our models. Since the data is highly imbalanced, it is important to stratify across the data sets to ensure an even distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.1, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2 Applying SMOTE\n",
    "<a id=section_3_2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio in oversampling and the sampling strategy for undersampling are very important in improving the performance of the models. We have selected ratios based ased on research from https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0225-0 for this dataset. However, try to expirement with different ratios to see the impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class with SMOTE to a 1:4 ratio\n",
    "over = SMOTE(sampling_strategy=0.25)\n",
    "\n",
    "# Undersample the majority class to achieve about a 1:1 ratio.\n",
    "# The minority class will be the same amount (1 to 1) as the majority class\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "\n",
    "# Add steps to parameter list\n",
    "steps = [('o', over), ('u', under)]\n",
    "\n",
    "# Create imblearn.pipeline and pass steps\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Fit and apply to the CMS dataset in a single transform\n",
    "X_smote, y_smote = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.3 Check for imbalance\n",
    "<a id=section_3_3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the target (fraudulent_provider) value counts to check for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(Counter(y_smote).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.4 Split SMOTE augmented dataset\n",
    "<a id=section_3_4></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_train, X_smote_validation, y_smote_train, y_smote_validation = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.1, stratify=y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.5 Prepare training data for uploading\n",
    "<a id=section_3_5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first copy the data to an in-memory buffer and then upload the data to S3 in libsvm format (XGBoost can take either libsvm or csv files as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an in-memory buffer instead of a file\n",
    "buf = io.BytesIO()\n",
    "\n",
    "# Transform the dataset in libsvm/svmlight file format\n",
    "sklearn.datasets.dump_svmlight_file(X_smote_train, y_smote_train, buf)\n",
    "\n",
    "# Set pointer to the beginning of the file\n",
    "buf.seek(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.6 Upload training data to S3\n",
    "<a id=section_3_6></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path in S3\n",
    "key = 'fraud-dataset'\n",
    "subdir = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload data to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', subdir, key)).upload_fileobj(buf)\n",
    "\n",
    "# Display the S3 training data location\n",
    "s3_train_data = 's3://{}/{}/train/{}/{}'.format(bucket, prefix, subdir, key)\n",
    "print('Uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.7 Prepare validation data for uploading\n",
    "<a id=section_3_7></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an in-memory buffer instead of a file\n",
    "buf = io.BytesIO()\n",
    "\n",
    "# Transform the dataset in libsvm/svmlight file format\n",
    "sklearn.datasets.dump_svmlight_file(X_smote_validation, y_smote_validation, buf)\n",
    "\n",
    "# Set pointer to the beginning of the file\n",
    "buf.seek(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.8 Upload validation data to S3\n",
    "<a id=section_3_8></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to S3\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', subdir, key)).upload_fileobj(buf)\n",
    "\n",
    "# Display the S3 validation data location\n",
    "s3_validation_data = 's3://{}/{}/validation/{}/{}'.format(bucket, prefix, subdir, key)\n",
    "print('Uploaded validation data location: {}'.format(s3_validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Model Training\n",
    "<a id=section_4_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Get the container URI for running XGBoost\n",
    "<a id=section_4_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Amazon XGBoost supervised learning algorithm for classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the ECR URI for the pre-built SageMaker XGBoost Docker image\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker abstracts training via Estimators. We can pass the classifier and parameters along with hyperparameters to the estimator, and fit the estimator to the data in S3. An important parameter here is `scale_pos_weight` which scales the weights of the positive vs. negative class examples. This is crucial to do in an imbalanced dataset like the one we are using here, otherwise the majority class would dominate the learning.\n",
    "\n",
    "The other hyperparameters seen here were based on the results of the Hyperparameter Optimization performed using SageMaker. We describe that technique in the next section of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Rebalance positive and negative weights\n",
    "<a id=section_4_2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the data set is so highly skewed, we set the scale position weight conservatively,\n",
    "# as sqrt(num_nonfraud/num_fraud).\n",
    "# Other recommendations for the scale_pos_weight are setting it to (num_nonfraud/num_fraud).\n",
    "scale_pos_weight = sqrt(np.count_nonzero(y_train==0)/np.count_nonzero(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Train the model\n",
    "<a id=section_4_3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators are a high level interface for SageMaker training for handling end-to-end Amazon SageMaker training and deployment tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hyperparams = {\n",
    "    \"max_depth\":7,\n",
    "    \"subsample\":0.8,\n",
    "    \"num_round\":145,\n",
    "    \"eta\":0.82,\n",
    "    \"gamma\":4,\n",
    "    \"min_child_weight\":41.08,\n",
    "    \"silent\":0,\n",
    "    \"objective\":'binary:logistic',\n",
    "    \"eval_metric\":'auc',\n",
    "    \"scale_pos_weight\": scale_pos_weight\n",
    "}\n",
    "\n",
    "clf = sagemaker.estimator.Estimator(container,\n",
    "                                    get_execution_role(),\n",
    "                                    hyperparameters=hyperparams,\n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_location,\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "clf.fit({'train': s3_train_data, 'validation': s3_validation_data })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Model Hosting\n",
    "<a id=section_5_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Create a real-time inference endpoint\n",
    "<a id=section_5_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy the estimator to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Serialize data to a CSV-formatted string\n",
    "csv_serializer = CSVSerializer()\n",
    "\n",
    "# Create a real-time inference endpoint that hosts our trained model \n",
    "xgb_predictor = clf.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m4.xlarge', \n",
    "                       serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Model Evaluation\n",
    "<a id=section_6_0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained the model we can use it to make predictions for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Create a wrapper function for model testing\n",
    "<a id=section_6_1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we have a large test set, we call predict on smaller batches\n",
    "def predict(current_predictor, df, rows=500):\n",
    "    \"\"\"\n",
    "    A wrapper function to invoke the Estimator's predict function using\n",
    "    a for loop. \n",
    "    \n",
    "    Parameters:\n",
    "        current_predictor: The sagemaker.estimator.Estimator object\n",
    "        df: a DataFrame object containing observations without the target feature\n",
    "        rows: number of observations passed to the predict function per batch\n",
    "      \n",
    "    Returns:\n",
    "        predictions: An array of predictions (of dtype float64)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split an array into multiple sub-arrays by dividing num of observations by rows parameter\n",
    "    split_array = np.array_split(df, int(df.shape[0] / float(rows) + 1))\n",
    "    \n",
    "    # Initialize variable to store prediction results\n",
    "    predictions = ''\n",
    "    \n",
    "    # Call the Estimator's predict function\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, current_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    # Return\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Test the model\n",
    "<a id=section_6_2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test the model by invoking the real-time inference endpoint with observations from the test dataset\n",
    "raw_preds = predict(xgb_predictor, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Calculate balanced accuracy scores\n",
    "<a id=section_6_3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a few measures from the scikit-learn package to evaluate the performance of our model. When dealing with an imbalanced dataset, we need to choose metrics that take into account the frequency of each class in the data.\n",
    "\n",
    "We will use [balanced accuracy score](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score)\n",
    "\n",
    "We can bring a balance between the metrics again by adjusting our classification threshold (threshold between labeling a point as fraud or not). We can try different thresholds to see if they affect the result of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate balanced accuracy scores for different threshold values\n",
    "proposed_treshold = 0.0\n",
    "proposed_score = 0.0\n",
    "\n",
    "for thres in np.linspace(0.1, 0.99, num=10):\n",
    "    smote_thres_preds = np.where(raw_preds > thres, 1, 0)\n",
    "    score = balanced_accuracy_score(y_test, smote_thres_preds)\n",
    "    print(\"Threshold: {:.1f}\".format(thres))\n",
    "    print(\"Balanced accuracy = {:.3f}\".format(score))\n",
    "    \n",
    "    # Set the max score    \n",
    "    if proposed_score <= score:\n",
    "        proposed_score = score\n",
    "        proposed_treshold = thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best thresholds from the above\n",
    "y_preds = np.where(raw_preds >= proposed_treshold, 1, 0)\n",
    "print(\"Balanced accuracy = {}\".format(balanced_accuracy_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Plot results in a confusion matrix\n",
    "<a id=section_6_4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from single-value metrics, it's also useful to look at metrics that indicate performance per class. A confusion matrix, and per-class precision, recall and f1-score can also provide more information about the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_predicted):\n",
    "\n",
    "    cm  = confusion_matrix(y_true, y_predicted)\n",
    "    # Get the per-class normalized value for each cell\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # We color each cell according to its normalized value, annotate with exact counts.\n",
    "    ax = sns.heatmap(cm_norm, annot=cm, fmt=\"d\")\n",
    "    ax.set(xticklabels=[\"non-fraud\", \"fraud\"], yticklabels=[\"non-fraud\", \"fraud\"])\n",
    "    ax.set_ylim([0,2])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.5 Display Classification Report\n",
    "<a id=section_6_5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_test, y_preds, target_names=['non-fraud', 'fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report transposed \n",
    "df_classification_report_smote = pd.DataFrame(\n",
    "    classification_report(y_test, \n",
    "                          y_preds, \n",
    "                          target_names=['non-fraud', 'fraud'], \n",
    "                          output_dict=True)).T\n",
    "\n",
    "df_classification_report_smote['support'] = df_classification_report_smote.support.apply(int)\n",
    "\n",
    "df_classification_report_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.6 Training without SMOTE (Optional)\n",
    "<a id=section_6_6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll perform the same training, hosting and model evaluation steps on the original dataset, then compare the classification reports between the original dataset and the SMOTE augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Converts data to SVM format and returns a in-memory buffer\n",
    "def convertToSVM(X, y):\n",
    "    buf = io.BytesIO()\n",
    "    sklearn.datasets.dump_svmlight_file(X, y, buf)\n",
    "    buf.seek(0);\n",
    "    \n",
    "    # Return    \n",
    "    return buf\n",
    "\n",
    "\n",
    "# Uploads an in-memory buffer as a file to a specified S3 location\n",
    "def uploadToS3(path, buf):\n",
    "    \n",
    "    # Set the directory path in S3\n",
    "    key = 'fraud-dataset-original'\n",
    "    subdir = 'base'\n",
    "    \n",
    "    # Upload to S3\n",
    "    boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, path, subdir, key)).upload_fileobj(buf)\n",
    "    s3_input_location = 's3://{}/{}/train/{}/{}'.format(bucket, prefix, subdir, key)\n",
    "    s3_output_location = 's3://{}/{}/{}/output'.format(bucket, prefix, key)\n",
    "    \n",
    "    # Return\n",
    "    return (s3_input_location, s3_output_location)\n",
    "\n",
    "\n",
    "# Convert datasets to SVM and load into in-memory buffer\n",
    "train_svm = convertToSVM(X_train, y_train)\n",
    "test_svm = convertToSVM(X_test, y_test)\n",
    "\n",
    "# Upload training and test datasets\n",
    "s3_orig_train_data, s3_output_location = uploadToS3('train', train_svm)\n",
    "s3_orig_test_data, s3_output_location = uploadToS3('test', test_svm)\n",
    "\n",
    "# We'll reuse the Estimator from above for to train\n",
    "clf.output_path = s3_output_location\n",
    "clf.fit({'train': s3_orig_train_data, 'validation': s3_orig_test_data })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Serialize data to a CSV-formatted string\n",
    "csv_serializer = CSVSerializer()\n",
    "\n",
    "# Create a real-time inference endpoint that hosts our trained model \n",
    "xgb_predictor_orig = clf.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m4.xlarge', \n",
    "                       serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test the model by invoking the real-time inference endpoint with observations from the test dataset\n",
    "y_preds_orig = predict(xgb_predictor_orig, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_preds_orig.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_test, y_preds_orig.round(), target_names=['non-fraud', 'fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report transposed \n",
    "df_classification_report_orig = pd.DataFrame(\n",
    "    classification_report(y_test, \n",
    "                          y_preds_orig.round(), \n",
    "                          target_names=['non-fraud', 'fraud'], \n",
    "                          output_dict=True)).T\n",
    "\n",
    "df_classification_report_orig['support'] = df_classification_report_orig.support.apply(int)\n",
    "\n",
    "df_classification_report_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the original (no SMOTE) and SMOTE classification reports\n",
    "df_classification_report_orig.compare(df_classification_report_smote, align_axis=0).rename(index={'self': 'No SMOTE', 'other': 'SMOTE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the CMS dataset is **highly imbalanced** and the objective of the model is to correctly identify **fradulent** transactions (minority class), we will focus on the **recall** and **f-1 metrics** for evaluating model performance. By applying SMOTE to the minority class and RandomUnderSampler to the majority class, the recall score increased from .26 to .98. Additionally, the f1-score improved from .35 to .57. Interestingly, the precision score decreased from .54 to .40 for the minority class, but increased from .93 to .99 for the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up endpoints\n",
    "# xgb_predictor.delete_endpoint()\n",
    "# xgb_predictor_orig.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acknowledgements\n",
    "\n",
    "The dataset used to demonstrated the fraud detection solution has been collected and analysed from CMS \n",
    "\n",
    "https://data.cms.gov/provider-summary-by-type-of-service/medicare-physician-other-practitioners/medicare-physician-other-practitioners-by-provider-and-service\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
